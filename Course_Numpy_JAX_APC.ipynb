{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEFSNy7IucZLJRXuhQZvQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pchanial/python-for-data-scientists/blob/master/Course_Numpy_JAX_APC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy & JAX\n",
        "\n",
        "- Numpy: provides a powerful array model and vectorized functions for mathematical computations. It is CPU-only.\n",
        "\n",
        "- JAX: JIT compilations of Python functions, and more (autodifferentiation, vectorization, parallelization). Can work on GPUs, TPUs.\n",
        "\n",
        "Most of the Numpy library has been re-implemented in JAX, so if Numpy is familiar to you, JAX will be (with many caveats)."
      ],
      "metadata": {
        "id": "Put1DYEP_i8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives of the course:\n",
        "- Understand why Numpy is faster than Vanilla Python\n",
        "- Understand why JAX is faster than Numpy\n",
        "- Numpy concepts no more applicable to JAX\n",
        "- Numpy concepts still applicable to JAX\n"
      ],
      "metadata": {
        "id": "ShXME5SJBO_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports necessary for the course\n",
        "import timeit\n",
        "from typing import Any, Callable, Sequence\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jaxlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mp\n",
        "#import polars as pl\n",
        "\n",
        "print('Devices:', jax.devices())\n",
        "import time\n",
        "\n",
        "\n",
        "# helpers\n",
        "def pointer(x: np.ndarray) -> int:\n",
        "  \"\"\"Returns the memory address of the first array element.\"\"\"\n",
        "  return x.__array_interface__['data'][0]\n",
        "\n",
        "\n",
        "def bench_one(func: Callable[[], Any]) -> float:\n",
        "    \"\"\"Returns execution time in s.\"\"\"\n",
        "    repeat = 7\n",
        "    timer = timeit.Timer(func)\n",
        "    number, _ = timer.autorange()\n",
        "    runs = np.array([_ / number for _ in timer.repeat(repeat=repeat, number=number)])\n",
        "    runs_ms = runs * 1000\n",
        "    print(f'{np.min(runs_ms):.3f} ms ± {np.std(runs_ms) * 1000:.2f} µs (min ± std. dev. of {repeat} runs, {number} loops each)')\n",
        "    return np.min(runs)\n",
        "\n",
        "\n",
        "def bench(func: Callable, values: Sequence[Any], *, setup: Callable | None = None) -> list[float]:\n",
        "    elapsed_times = []\n",
        "    for value in values:\n",
        "        if setup is not None:\n",
        "            args = setup(value)\n",
        "        else:\n",
        "            args = (value,)\n",
        "        if isinstance(func, jaxlib.xla_extension.PjitFunction):\n",
        "            func(*args)\n",
        "            benchmarked_func = lambda: func(*args).block_until_ready()\n",
        "        else:\n",
        "            benchmarked_func = lambda: func(*args)\n",
        "        elapsed_times.append(bench_one(benchmarked_func))\n",
        "    return elapsed_times\n",
        "\n",
        "\n",
        "def bench_many(funcs: Sequence[Callable], values: Sequence[Any], setups: Sequence[Callable | None], labels: Sequence[str]) -> None:\n",
        "    for func, setup, label in zip(funcs, setups, labels):\n",
        "        run_times = bench(func, values, setup=setup)\n",
        "        mp.loglog(values, run_times, marker='.', label=label)\n",
        "    mp.ylabel('Elapsed time [s]')\n",
        "    mp.legend()\n"
      ],
      "metadata": {
        "id": "fH2LxsS8Gx5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409614a6-2290-4429-a9a7-e0ba006b7bec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Devices: [CpuDevice(id=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why is Numpy faster than Vanilla Python\n",
        "\n",
        "![numpy-vs-python](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-vs-python.png)\n",
        "\n",
        "The Numpy array model is quite powerful, but before delving into the details on how Numpy arrays can be manipulated, it is interesting to understand why they are much more efficient than Python lists.\n",
        "\n",
        "- first, when a Numpy array is created, its elements are stored one next to the other (the memory storage is contiguous, see figure on the left for a 2-dimensional array), whereas in a Python list, elements are created before the list and they can be stored wherever in the memory (the memory storage is scattered, see figure on the right). In most systems, data from the main memory is transferred to the CPU via layers of caches, which implies that memory transfers from the cache to the CPU involve whole chunks of contiguous memory (a cache line) even if only few bytes in the cache line are actually requested by the CPU. As a consequence, a non-contiguous memory storage of the data will force the transfer of unneeded data from the cache and will incur a bandwidth penalty.\n",
        "\n",
        "- Vanilla Python memory layout\n",
        "\n",
        "![list of list](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/gh-pages/source/layout_listoflist.png)\n",
        "\n",
        "- Numpy memory layout\n",
        "\n",
        "![ndarray](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/gh-pages/source/layout_2darray.png)\n",
        "\n",
        "- modern architectures also have the possibility to anticipate transfers from the memory by prefetching the next cache lines. This mechanism will obviously better work when the data storage is contiguous.\n",
        "\n",
        "- in Numpy, all elements occupy the same number of bytes, and as a consequence, the location of an element in the memory (its address) can be cheaply computed from its index and the location of the first element. There is no such relationship in Python lists: the location of each element has to be stored in the memory, so that every read or write access has the indirection overhead of transferring this element location to the CPU beforehand.\n",
        "\n",
        "- SIMD instructions can operate on several data in a single CPU cycle, as long as they are contiguous\n",
        "\n",
        "### Numpy array model\n",
        "\n",
        "![Numpy array model](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-array-model.png)\n",
        "\n",
        "\n",
        "\n",
        "For writing efficient code for Numpy and JAX, one should think in terms of vectors, matrices or tensors to reduce the back and forth between the low-level implementation of mathematical functions and the Python interpreter.\n",
        "\n",
        "### Example:\n",
        "Numpy's C code uses a lot of macro and pre-processing to specialise the different datatypes and\n",
        "contiguity configurations between the operands. This work is not done by JAX: outside of JIT all arrays are contiguous.\n",
        "\n",
        "![Numpy loops](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-loop.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "13pGK76QCq7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice**: Wave the for loops goodbye!\n",
        "\n",
        "Compute $\\pi$, as given by the Madhava formula\n",
        "$\\pi = \\sqrt{12}\\sum^\\infty_{k=0} \\frac{(-\\frac{1}{3})^{k}}{2k+1}$.\n",
        "The $k$ indices ranging from 0 to (let’s say) 29 will be returned by the NumPy function `arange` (see above) and $\\pi$ will be computed by calling another NumPy function (`sum`), instead of using a for loop."
      ],
      "metadata": {
        "id": "iV9Bk-n1_Ufj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 30\n",
        "pi = ...\n",
        "assert abs(pi - np.pi) < 1e-15"
      ],
      "metadata": {
        "id": "H9nSx4gT_UA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why is JAX faster than Numpy\n",
        "\n",
        "JAX has a Just-In-Time compiler (XLA). This compiler can perform many whole-program optimizations:\n",
        "- operation fusion (or kernel fusion) is the flagship feature of XLA\n",
        "- specializing to known tensor shapes, allowing for more aggressive constant propagation or loop unrolling\n",
        "- analyzing and scheduling memory usage to eliminate intermediate storage buffers\n",
        "- substituting inplace operations for copies\n",
        "- removing dead branches and only computing subsets of requested values if not all of them are being returned\n",
        "\n",
        "### Example 1: kernel fusion\n",
        "\n",
        "With JAX, it is easy to inspect the computational graphs of compiled and non-compiled functions. The internal representation, which is fed to the XLA compiler is called HLO.\n",
        "\n",
        "In this simple example, we have two sequential operations:\n",
        "- multiply by 3\n",
        "- add 2\n",
        "\n",
        "```python\n",
        "def f(x):\n",
        "  return 3 * x + 2\n",
        "```\n",
        "\n",
        "- Non-compiled computation graph: the first operation is performed on the input array and the second one is applied on the result (like Numpy)\n",
        "\n",
        "![HLO non-optimized](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/hlo-non-optimized.png)\n",
        "\n",
        "- Compiled computation graph: the for loops are fused, the tow operations are both performed at each iteration (unlike Numpy)\n",
        "\n",
        "![HLO optimized](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/hlo-optimized.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "aC5j1YlhCwHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [2**n for n in range(10, 24)]\n",
        "\n",
        "setup_numpy = lambda n: (np.arange(n, dtype=np.float32),)\n",
        "setup_jax = lambda n: (jnp.arange(n, dtype=np.float32),)\n",
        "results = bench_many(\n",
        "    [np.sum, jax.jit(jnp.sum)],\n",
        "    values,\n",
        "    setups=[setup_numpy, setup_jax],\n",
        "    labels=['numpy', 'jax'],\n",
        ")\n",
        "mp.title('sum(x)')"
      ],
      "metadata": {
        "id": "W44ezrmf7mFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = [2**n for n in range(10, 24)]\n",
        "\n",
        "setup_numpy = lambda n: (np.random.normal(size=n).astype(np.float32), np.random.normal(size=n).astype(np.float32))\n",
        "key = jax.random.key(0)\n",
        "key1, key2 = jax.random.split(key)\n",
        "setup_jax = lambda n: (jax.random.normal(key1, (n,), np.float32), jax.random.normal(key2, (n,), np.float32))\n",
        "\n",
        "bench_many(\n",
        "    [lambda x, y: 2 * x * y + 3 * y + 1, jax.jit(lambda x, y: 2 * x * y + 3 * y + 1)],\n",
        "    values,\n",
        "    setups=[setup_numpy, setup_jax],\n",
        "    labels=['numpy', 'jax'],\n",
        ")\n",
        "mp.title('2xy + 3y + 1')"
      ],
      "metadata": {
        "id": "nrORVvCP0T-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Example 2: Jit can remove useless computations"
      ],
      "metadata": {
        "id": "rv4XUXI-7rKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = [4**n for n in range(5, 12)]\n",
        "\n",
        "key = jax.random.key(0)\n",
        "setup = lambda n: (jax.random.normal(key, (n,)),)\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def f(x):\n",
        "    return jnp.exp(x)\n",
        "\n",
        "@jax.jit\n",
        "def f_subset(x):\n",
        "    return jnp.exp(x)[:2]\n",
        "\n",
        "bench_many(\n",
        "    [f, f_subset],\n",
        "    values,\n",
        "    setups=[setup, setup],\n",
        "    labels=['whole', 'subset'],\n",
        ")"
      ],
      "metadata": {
        "id": "E0M5Vipd7g8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Numpy concepts not applicable to JAX\n",
        "\n",
        "1. Vues vs copies\n",
        "\n",
        "Outside of jit (for non-compiled functions), JAX arrays are contiguous. For example, a slice results in a copy. Inside jit, the choice of having vues instead of copies is handed over to the compiler (XLA).\n",
        "\n",
        "2. Inplace operations\n",
        "\n",
        "JAX arrays are immutable, so they can only be copied outside of jit. Inside jit, it is again the responsability of the XLA compiler to perform the actual operations inplace.\n",
        "\n",
        "3. Data type promotion rules\n",
        "\n",
        "JAX and Numpy do not have the same promotion rules.\n",
        "- Numpy favors the data integrity and will upcast in order not to loose information (versions < 2.0 even look at the values in some cases before upcasting)\n",
        "- JAX is more pragmatic and broadly speaking tries to avoid changing the number of bytes encoding and have a predictable associative rules (unlike Numpy) for type promotion.\n",
        "\n",
        "4. Non-number data types\n",
        "\n",
        "Datetimes, string and object data types have no JAX equivalent. Use Pandas or Polars instead.\n",
        "\n",
        "5. Structured arrays\n",
        "\n",
        "Structured dtypes (aka records) are not implemented in JAX . Use JAX PyTrees.\n",
        "\n",
        "4. Random library\n",
        "\n",
        "The Numpy random library has not been ported to jax.numpy, because Numpy uses a global state for the pseudo random generator, which is incompatible with parallelization. Use jax.random instead."
      ],
      "metadata": {
        "id": "BhPtfdQDBTcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Numpy concepts still applicable to JAX\n",
        "\n",
        "- indexing\n",
        "- array creation\n",
        "- array manipulation\n",
        "- broadcasting\n",
        "- ufunc methods\n",
        "\n"
      ],
      "metadata": {
        "id": "a0twBSxzBVzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing\n",
        "\n",
        "![Numpy indexing](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-indexing.png)\n"
      ],
      "metadata": {
        "id": "P2aztBSEB_8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Array creation\n",
        "\n",
        "![Array creation 1](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-creation1.png)\n",
        "\n",
        "![Array creation 2](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-creation2.png)\n",
        "\n",
        "![Array creation 3](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-creation3.png)\n",
        "\n",
        "![Array creation 4](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-creation4.png)\n",
        "\n",
        "![Array creation 5](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-creation5.png)\n"
      ],
      "metadata": {
        "id": "xJbL1ecPA9Qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Array manipulation\n",
        "\n",
        "![Array manipulation](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-array-manipulation.png)\n",
        "\n",
        "![Array combining](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-array-combining.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "mKpUA9RCBY1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Broadcasting\n",
        "1. What is Broadcasting?\n",
        "\n",
        "Broadcasting is a powerful feature of Numpy (and JAX) that allows operations (such as addition, multiplication etc.) which are normally element-wise to be carried out on arrays of different shapes without having to manually resize them. In other words, broadcasting automatically expands the dimensions of arrays to be the same size before operating them together. It can be seen as a generalization of operations involving an array and a scalar.\n",
        "\n",
        "2. Advantages of Broadcasting\n",
        "\n",
        "- Simplicity: Broadcasting simplifies the code by avoiding the need to manually resize tables.\n",
        "- Performance: Broadcasting improves performance by avoiding data duplication.\n",
        "- Readability: Broadcasting makes the code more concise\n",
        "\n",
        "3. Examples\n",
        "\n",
        "- the addition of a scalar on an matrix can be seen as the addition of a matrix with identical elements (and same dimensions).\n",
        "\n",
        "![broadcast scalar](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/gh-pages/source/broadcast_scalar.png)\n",
        "\n",
        "- the addition of a row on a matrix will be seen as the addition of a matrix with replicated rows (the number of columns must match).\n",
        "\n",
        "![broadcast column](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/gh-pages/source/broadcast_column.png)\n",
        "\n",
        "- conversely the addition of a column on a matrix will be seen as the addition of a matrix with replicated columns (the number of rows must match)\n",
        "\n",
        "![broadcast row](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/gh-pages/source/broadcast_row.png)\n",
        "\n",
        "What if the rank of the arrays is greater than 2? There is no restriction on the rank: any dimension of length 1 is broadcastable and is virtually replicated to match the other array’s dimension length. The two arrays may have different broadcastable dimensions. If this happens, the result of the operation will have more elements than any of the operands.\n",
        "\n",
        "Can it work on arrays of different ranks? Sure! Dimensions of length 1 are prepended (added on the left of the array shape) until the two arrays have the same rank. As a consequence, the following operation is possible:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kZQTTlNrCKpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((5, 9)) + np.ones(9)"
      ],
      "metadata": {
        "id": "oqaSHRldi26d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "but not this one, since the righmost dimensions are different:\n"
      ],
      "metadata": {
        "id": "lACNsAJUjShB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((5, 9)) + np.ones(5)"
      ],
      "metadata": {
        "id": "V0BVuIeHi2rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix it, an additional dimension must be specified and added on the right:\n"
      ],
      "metadata": {
        "id": "qo_B8N0YjTFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((5, 9)) + np.ones(5)[:, None]  # or np.newaxis instead of None"
      ],
      "metadata": {
        "id": "DhTRX5C8itvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check that broadcasting does not require additional memory. There is no replication along the \"missing\" dimensions, because a stride of zero is used. This is why broadcasting is a very cheap operation."
      ],
      "metadata": {
        "id": "mz1yroAhlWXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = np.ones((4, 1))\n",
        "a2 = np.ones((2, 1, 3))\n",
        "a1_broadcast, a2_broadcast = np.broadcast_arrays(a1, a2)\n",
        "print('broadcast shapes:', a1_broadcast.shape, a2_broadcast.shape)\n",
        "print('same memory layout:', pointer(a1) == pointer(a1_broadcast))\n",
        "print(f'{a1.strides=}', f'{a1_broadcast.strides=}')"
      ],
      "metadata": {
        "id": "iCMjHYzFd_VG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f93d0fb-51b2-4110-e406-75298260062b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "broadcast shapes: (2, 4, 3) (2, 4, 3)\n",
            "same memory layout: True\n",
            "a1.strides=(4, 4) a1_broadcast.strides=(0, 4, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should use broadcasting wherever possible, just keep an eye on the size of the broadcast result to make sure that it does not become too large."
      ],
      "metadata": {
        "id": "FNZvVry8iuXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.broadcast_shapes((3, 1, 4), (3, 4), (7, 1, 1, 1))"
      ],
      "metadata": {
        "id": "JX6ER2ZydlOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1**: Can the arrays of the following shapes be broadcast together? If yes, what would be the shape of the result?\n",
        "\n",
        "    (7, 1) and (7, 4)\n",
        "    (7,) and (4, 7)\n",
        "    (3, 3) and (2, 3)**texte en gras**\n",
        "    (1, 1, 1, 8) and (1, 9, 1)\n",
        "    (4, 1, 9) and (3, 1)"
      ],
      "metadata": {
        "id": "B9UJ6CJImTDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2**: Remove the for loops in this code by using broadcasting and measure the improvement in execution time.\n"
      ],
      "metadata": {
        "id": "wB62V1FEnd9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as mp\n",
        "import numpy as np\n",
        "\n",
        "NDETECTOR = 8\n",
        "NSAMPLE = 1000\n",
        "SAMPLING_PERIOD = 0.1\n",
        "GLITCH_TAU = 0.3\n",
        "GLITCH_AMPL = 20\n",
        "GAIN_SIGMA = 0.03\n",
        "SOURCE_AMPL = 7\n",
        "SOURCE_PERIOD = 5\n",
        "NOISE_SIGMA = 0.7\n",
        "\n",
        "time = np.arange(NSAMPLE) * SAMPLING_PERIOD\n",
        "glitch = np.zeros(NSAMPLE)\n",
        "glitch[100:] = GLITCH_AMPL * np.exp(-time[:-100] / GLITCH_TAU)\n",
        "gain = 1 + GAIN_SIGMA * np.random.standard_normal(NDETECTOR)\n",
        "offset = np.arange(NDETECTOR)\n",
        "source = SOURCE_AMPL * np.sin(2 * np.pi * time / SOURCE_PERIOD)\n",
        "noise = NOISE_SIGMA * np.random.standard_normal((NDETECTOR, NSAMPLE))\n",
        "\n",
        "signal = np.empty((NDETECTOR, NSAMPLE))\n",
        "for idet in range(NDETECTOR):\n",
        "    for isample in range(NSAMPLE):\n",
        "        signal[idet, isample] = (\n",
        "            gain[idet] * source[isample]\n",
        "            + glitch[isample]\n",
        "            + offset[idet]\n",
        "            + noise[idet, isample]\n",
        "        )\n",
        "\n",
        "mp.figure()\n",
        "mp.subplot(211)\n",
        "mp.imshow(signal, aspect='auto', interpolation='none')\n",
        "mp.xlabel('sample')\n",
        "mp.ylabel('detector')\n",
        "mp.subplot(212)\n",
        "for s in signal:\n",
        "    mp.plot(time, s)\n",
        "mp.xlabel('time [s]')\n",
        "mp.ylabel('signal')\n",
        "mp.show()\n"
      ],
      "metadata": {
        "id": "PeDj1ZwEniMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3**: Write a one-liner function that normalizes by the euclidian norm M N-dimensional real vectors packed in an array of shape (M, N). Bonus if the function works with a tensor of any rank, such as (P, Q, M, N)."
      ],
      "metadata": {
        "id": "HdUUL8AcoR7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fast_normalize(v):\n",
        "    return v / ???\n",
        "\n",
        "vectors = np.random.normal(size=(10, 3))\n",
        "expected_normalized_vectors = vectors.copy()\n",
        "for vector in expected_normalized_vectors:\n",
        "    vector /= np.sqrt(vector[0]**2 + vector[1]**2 + vector[2]**2)\n",
        "actual_normalized_vectors = fast_normalize(vectors)\n",
        "\n",
        "assert np.allclose(actual_normalized_vectors, expected_normalized_vectors)"
      ],
      "metadata": {
        "id": "zQErOn1UogVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 4**: Using broadcasting, write in one line the multiplication of a vector of size P with a tensor of arbitrary rank and of shape (P, Q, R, ...)."
      ],
      "metadata": {
        "id": "y3umOwavnhfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = np.array([1, 2, 3, 4])\n",
        "tensor = np.arange(4*2*2*3).reshape(4, 2, 2, 3)\n",
        "\n",
        "product = ???\n",
        "\n",
        "assert np.allclose(product, np.array([vector[i] * tensor[i] for i in range(4)]))"
      ],
      "metadata": {
        "id": "73deFOjzoYJK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Universal function methods\n",
        "\n"
      ],
      "metadata": {
        "id": "0NbeNFCcCTaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Ufunc 1](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-ufunc1.png)\n",
        "\n",
        "![Ufunc 2](https://raw.githubusercontent.com/pchanial/python-for-data-scientists/master/images/numpy-ufunc2.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "FtTdXD-4r79w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0p3dh9O4GrV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}